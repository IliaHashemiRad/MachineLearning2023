# ğŸ§  Machine Learning Projects Portfolio

> A curated collection of academic computer vision and probabilistic modeling projects, featuring deep learning pipelines for restoration tasks and Gaussian Mixture Model (GMM) methods for statistical inference.

![Python](https://img.shields.io/badge/Python-3.x-blue?logo=python)
![Jupyter](https://img.shields.io/badge/Notebook-Jupyter-orange?logo=jupyter)
![PyTorch](https://img.shields.io/badge/Framework-PyTorch-red?logo=pytorch)
![Scikit--learn](https://img.shields.io/badge/ML-scikit--learn-f7931e?logo=scikitlearn)

---

## ğŸ“Œ Overview

This repository contains five hands-on projects developed for computer vision and machine learning coursework. Together, they cover:

- ğŸ–¼ï¸ **Image restoration tasks** using neural networks (denoising, super-resolution, colorization)
- ğŸ“Š **Probabilistic modeling** using Gaussian Mixture Models (EM and MAP-based estimation)
- ğŸ§ª **Notebook-based experiments** including training, evaluation, and visual analysis

The codebase is organized around end-to-end experimental workflows, with each project in its own folder.

---

## ğŸ“‚ Repository Structure

```text
MachineLearning2023/
â”œâ”€â”€ Image Denoising/
â”‚   â”œâ”€â”€ Image Denoising.ipynb
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ Image Super Resolution/
â”‚   â”œâ”€â”€ Image Super Resolution.ipynb
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ Image Colorization/
â”‚   â”œâ”€â”€ Image Colorization.ipynb
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ EM algorithm for GMM/
â”‚   â”œâ”€â”€ Phase1.ipynb
â”‚   â”œâ”€â”€ Phase 1.pdf
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ MAP of GMM/
â”‚   â”œâ”€â”€ Phase2.ipynb
â”‚   â”œâ”€â”€ Phase 2.pdf
â”‚   â””â”€â”€ README.md
â””â”€â”€ README.md
```

---

## ğŸš€ Projects

### 1) ğŸ”‡ Image Denoising (AutoEncoder + PCA Baseline)
- Builds a noisy MNIST pipeline and trains an AutoEncoder for denoising.
- Includes reconstruction visualization and comparison with a PCA-based approach.
- Focus: latent representation learning for noise removal.

### 2) ğŸ” Image Super Resolution (AutoEncoder)
- Trains a super-resolution model on an Unsplash-based dataset.
- Uses train/validation/test setup and visual inspection of restored outputs.
- Focus: recovering high-quality images from lower-resolution inputs.

### 3) ğŸ¨ Image Colorization (AutoEncoder)
- Trains colorization models from grayscale landscape inputs.
- Includes at least two modeling strategies and qualitative result analysis.
- Focus: learning color mappings from structural grayscale cues.

### 4) ğŸ“ˆ EM Algorithm for GMM (Phase 1)
- Implements EM steps manually (initialization, E-step, M-step).
- Explores clustering behavior and parameter estimation in mixture models.
- Focus: unsupervised density estimation and iterative optimization.

### 5) ğŸ§® MAP of GMM for Image Denoising (Phase 2)
- Uses patch-based modeling on MNIST with GMM priors and MAP estimation.
- Includes corruption setup, posterior-based patch reconstruction, and MSE analysis.
- Focus: Bayesian restoration with probabilistic image priors.

---

## ğŸ› ï¸ Tech Stack

- **Languages & Environment:** Python, Jupyter Notebook
- **Deep Learning:** PyTorch, torchvision
- **Classical ML & Statistics:** scikit-learn, SciPy, Keras/TensorFlow utilities
- **Data & Visualization:** NumPy, pandas, matplotlib, OpenCV

---

## â–¶ï¸ How to Run

1. Clone the repository:
   ```bash
   git clone <your-repo-url>
   cd MachineLearning2023
   ```
2. Open any project notebook in Jupyter/Colab.
3. Install required dependencies as needed (varies slightly per notebook).
4. Run cells sequentially and follow inline instructions.

> ğŸ’¡ Many notebooks include comments about optional long-running cells and model checkpoint usage.

---

## ğŸ“Š Outputs & Evaluation

Across projects, the repository demonstrates:

- Visual reconstruction quality checks (before/after comparisons)
- Learning curves for training/validation monitoring
- Quantitative metrics such as **MSE** in denoising workflows
- Comparative methods (e.g., AutoEncoder vs PCA)

---

## ğŸ“š Notes

- This repository is experiment-oriented and intended for educational/research demonstration.
- Some notebooks are computationally intensive depending on dataset size and hardware.

---

## ğŸ‘¨â€ğŸ’» Author

Developed as part of university coursework in machine learning course of Sharif University of Technology in 2023.
